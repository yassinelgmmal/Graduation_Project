{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/PaddlePaddle/PaddleOCR.git\n",
        "%cd PaddleOCR\n",
        "!pip install -r requirements.txt\n",
        "!pip install paddlepaddle paddleocr\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9iA-Tjw5Sobq",
        "outputId": "b2570cf9-a0fa-46c4-8578-3a8abdbc1e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PaddleOCR'...\n",
            "remote: Enumerating objects: 112878, done.\u001b[K\n",
            "remote: Counting objects: 100% (6653/6653), done.\u001b[K\n",
            "remote: Compressing objects: 100% (695/695), done.\u001b[K\n",
            "remote: Total 112878 (delta 6438), reused 5958 (delta 5958), pack-reused 106225 (from 3)\u001b[K\n",
            "Receiving objects: 100% (112878/112878), 690.75 MiB | 26.05 MiB/s, done.\n",
            "Resolving deltas: 100% (86889/86889), done.\n",
            "Updating files: 100% (2027/2027), done.\n",
            "/content/PaddleOCR\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.25.2)\n",
            "Collecting pyclipper (from -r requirements.txt (line 3))\n",
            "  Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting lmdb (from -r requirements.txt (line 4))\n",
            "  Downloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (1.26.4)\n",
            "Collecting rapidfuzz (from -r requirements.txt (line 7))\n",
            "  Downloading rapidfuzz-3.12.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.11.0.86)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (4.11.0.86)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (3.0.12)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (11.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (2.32.3)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (2.0.4)\n",
            "Requirement already satisfied: albucore in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (0.0.23)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (24.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 2)) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 2)) (2025.2.18)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->-r requirements.txt (line 2)) (0.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 13)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 13)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 13)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->-r requirements.txt (line 13)) (2025.1.31)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations->-r requirements.txt (line 14)) (2.10.6)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations->-r requirements.txt (line 14)) (4.11.0.86)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore->-r requirements.txt (line 16)) (3.12.1)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore->-r requirements.txt (line 16)) (6.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->-r requirements.txt (line 14)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->-r requirements.txt (line 14)) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->-r requirements.txt (line 14)) (4.12.2)\n",
            "Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (969 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.8/297.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.12.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyclipper, lmdb, rapidfuzz\n",
            "Successfully installed lmdb-1.6.2 pyclipper-1.3.0.post6 rapidfuzz-3.12.2\n",
            "Collecting paddlepaddle\n",
            "  Downloading paddlepaddle-2.6.2-cp311-cp311-manylinux1_x86_64.whl.metadata (8.6 kB)\n",
            "Collecting paddleocr\n",
            "  Downloading paddleocr-2.9.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from paddlepaddle) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.11/dist-packages (from paddlepaddle) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from paddlepaddle) (11.1.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from paddlepaddle) (4.4.2)\n",
            "Collecting astor (from paddlepaddle)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting opt-einsum==3.3.0 (from paddlepaddle)\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from paddlepaddle) (4.25.6)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.11/dist-packages (from paddleocr) (2.0.7)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from paddleocr) (0.25.2)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.11/dist-packages (from paddleocr) (0.4.0)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.11/dist-packages (from paddleocr) (1.3.0.post6)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.11/dist-packages (from paddleocr) (1.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from paddleocr) (4.67.1)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.11/dist-packages (from paddleocr) (3.12.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from paddleocr) (4.11.0.86)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from paddleocr) (4.11.0.86)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from paddleocr) (3.0.12)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from paddleocr) (6.0.2)\n",
            "Collecting python-docx (from paddleocr)\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from paddleocr) (4.13.3)\n",
            "Requirement already satisfied: fonttools>=4.24.0 in /usr/local/lib/python3.11/dist-packages (from paddleocr) (4.56.0)\n",
            "Collecting fire>=0.3.0 (from paddleocr)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from paddleocr) (2.32.3)\n",
            "Collecting albumentations==1.4.10 (from paddleocr)\n",
            "  Downloading albumentations-1.4.10-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting albucore==0.0.13 (from paddleocr)\n",
            "  Downloading albucore-0.0.13-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting tomli>=2.0.1 (from albucore==0.0.13->paddleocr)\n",
            "  Downloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.13->paddleocr) (4.12.2)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.13->paddleocr) (4.11.0.86)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.10->paddleocr) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.10->paddleocr) (1.6.1)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from albumentations==1.4.10->paddleocr) (2.10.6)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire>=0.3.0->paddleocr) (2.5.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->paddleocr) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->paddleocr) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->paddleocr) (2025.2.18)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->paddleocr) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->paddleocr) (0.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->paddleocr) (2.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->paddlepaddle) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx->paddlepaddle) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->paddlepaddle) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->paddlepaddle) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->paddlepaddle) (0.14.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from imgaug->paddleocr) (1.17.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from imgaug->paddleocr) (3.10.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx->paddleocr) (5.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->paddleocr) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->paddleocr) (2.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.0->albumentations==1.4.10->paddleocr) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.0->albumentations==1.4.10->paddleocr) (2.27.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.10->paddleocr) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.10->paddleocr) (3.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx->paddlepaddle) (1.3.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug->paddleocr) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug->paddleocr) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug->paddleocr) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug->paddleocr) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->imgaug->paddleocr) (2.8.2)\n",
            "Downloading paddlepaddle-2.6.2-cp311-cp311-manylinux1_x86_64.whl (126.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading paddleocr-2.9.1-py3-none-any.whl (544 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m544.7/544.7 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading albucore-0.0.13-py3-none-any.whl (8.5 kB)\n",
            "Downloading albumentations-1.4.10-py3-none-any.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.9/161.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (236 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.0/236.0 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=a923989d904ee66bd52faf819189df39fe5c91627c176fbab4f654ff97c54c1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built fire\n",
            "Installing collected packages: tomli, python-docx, opt-einsum, fire, astor, albucore, paddlepaddle, albumentations, paddleocr\n",
            "  Attempting uninstall: opt-einsum\n",
            "    Found existing installation: opt_einsum 3.4.0\n",
            "    Uninstalling opt_einsum-3.4.0:\n",
            "      Successfully uninstalled opt_einsum-3.4.0\n",
            "  Attempting uninstall: albucore\n",
            "    Found existing installation: albucore 0.0.23\n",
            "    Uninstalling albucore-0.0.23:\n",
            "      Successfully uninstalled albucore-0.0.23\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 2.0.4\n",
            "    Uninstalling albumentations-2.0.4:\n",
            "      Successfully uninstalled albumentations-2.0.4\n",
            "Successfully installed albucore-0.0.13 albumentations-1.4.10 astor-0.8.1 fire-0.7.0 opt-einsum-3.3.0 paddleocr-2.9.1 paddlepaddle-2.6.2 python-docx-1.1.2 tomli-2.2.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "opt_einsum"
                ]
              },
              "id": "2efccdc59dbc49bbbbab836979021373"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import paddleocr\n",
        "paddleocr.__version__\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aNFaeUG5SwJD",
        "outputId": "6c3f7cc7-3d67-4863-a2a3-5f68d094b93c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from paddleocr import PaddleOCR, draw_ocr\n",
        "from PIL import Image\n",
        "\n",
        "# Load the PaddleOCR model\n",
        "ocr_model = PaddleOCR(use_angle_cls=True, lang=\"en\")  # Use PP-OCRv3 with English\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xe9P_ssTKCC",
        "outputId": "ae6384eb-4aa6-4912-c33f-e6693e4d49f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_det_infer.tar to /root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer/en_PP-OCRv3_det_infer.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3910/3910 [00:15<00:00, 249.36it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download https://paddleocr.bj.bcebos.com/PP-OCRv4/english/en_PP-OCRv4_rec_infer.tar to /root/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer/en_PP-OCRv4_rec_infer.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:18<00:00, 547.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar to /root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer/ch_ppocr_mobile_v2.0_cls_infer.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2138/2138 [00:14<00:00, 146.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025/03/02 19:20:15] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/root/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/usr/local/lib/python3.11/dist-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Provide the path to your table image\n",
        "image_path = \"/content/scientific-table.jpg\"\n",
        "\n",
        "# Run OCR on the image\n",
        "result = ocr_model.ocr(image_path, cls=True)\n",
        "\n",
        "# Print results\n",
        "for line in result:\n",
        "    for word_info in line:\n",
        "        text, confidence = word_info[1][0], word_info[1][1]\n",
        "        print(f\"Detected text: {text} (Confidence: {confidence:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQj_jkXgTnH-",
        "outputId": "b8184180-5f68-478d-82ac-cedad8dc8967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025/03/02 19:24:44] ppocr DEBUG: dt_boxes num : 23, elapsed : 0.0716397762298584\n",
            "[2025/03/02 19:24:44] ppocr DEBUG: cls num  : 23, elapsed : 0.0651247501373291\n",
            "[2025/03/02 19:24:46] ppocr DEBUG: rec_res num  : 23, elapsed : 1.6349012851715088\n",
            "Detected text: Table 1.Exposure to salinity reduces the growth of wheat plants (Confidence: 0.95)\n",
            "Detected text: Group (Confidence: 1.00)\n",
            "Detected text: light (Confidence: 1.00)\n",
            "Detected text: 5days (Confidence: 0.99)\n",
            "Detected text: 10 days (Confidence: 0.95)\n",
            "Detected text: control (Confidence: 0.99)\n",
            "Detected text: 12 (Confidence: 1.00)\n",
            "Detected text: 70.32 (Confidence: 1.00)\n",
            "Detected text: 9010.5 (Confidence: 0.99)\n",
            "Detected text: test (Confidence: 0.99)\n",
            "Detected text: 12 (Confidence: 1.00)\n",
            "Detected text: 60.41.5* (Confidence: 0.98)\n",
            "Detected text: 787.9* (Confidence: 0.98)\n",
            "Detected text: control (Confidence: 1.00)\n",
            "Detected text: 16 (Confidence: 1.00)\n",
            "Detected text: 75.78. (Confidence: 0.93)\n",
            "Detected text: 1003 (Confidence: 1.00)\n",
            "Detected text: test (Confidence: 0.99)\n",
            "Detected text: 16 (Confidence: 1.00)\n",
            "Detected text: 52.22 (Confidence: 0.92)\n",
            "Detected text: 816.7 (Confidence: 1.00)\n",
            "Detected text: *P<0.05. (Confidence: 0.90)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Provide the path to your table image\n",
        "image_path = \"/content/paper.jpg\"\n",
        "\n",
        "# Run OCR on the image\n",
        "result = ocr_model.ocr(image_path, cls=True)\n",
        "\n",
        "# Print results\n",
        "for line in result:\n",
        "    for word_info in line:\n",
        "        text, confidence = word_info[1][0], word_info[1][1]\n",
        "        print(f\"Detected text: {text} (Confidence: {confidence:.2f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0ZPCJ82UxkY",
        "outputId": "992c1e19-1ba2-4553-c306-773a1f7d25d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025/03/02 19:26:32] ppocr DEBUG: dt_boxes num : 188, elapsed : 0.4913780689239502\n",
            "[2025/03/02 19:26:33] ppocr DEBUG: cls num  : 188, elapsed : 0.5187315940856934\n",
            "[2025/03/02 19:27:01] ppocr DEBUG: rec_res num  : 188, elapsed : 28.35664939880371\n",
            "Detected text: TABLE V: Comparison of the performance of fine tuning (Confidence: 0.99)\n",
            "Detected text: set and Shaila Pervin for her work in the development of the (Confidence: 1.00)\n",
            "Detected text: different pre-trained F-RCNN and M-RCNN models on the (Confidence: 0.99)\n",
            "Detected text: SPD data set. (Confidence: 1.00)\n",
            "Detected text: SPD documents. The performance scores are MAP @ IOU (Confidence: 0.99)\n",
            "Detected text: [0.50:0.95] evaluated via a 5-fold cross-document-validation (Confidence: 0.99)\n",
            "Detected text: REFERENCES (Confidence: 1.00)\n",
            "Detected text: on 20 SPD documents. The results demonstrate the advantage (Confidence: 0.99)\n",
            "Detected text: [1] P. W. J. Staar, M. Dolfi., C. Auer, and C. Bekas, Corpus conversion (Confidence: 0.98)\n",
            "Detected text: of PubLayNet over general image datasets in domain (Confidence: 0.96)\n",
            "Detected text: service: A machine learning platform to ingest documents at scale, (Confidence: 0.97)\n",
            "Detected text: adaptation for document layout analysis. (Confidence: 0.99)\n",
            "Detected text: in Proceedings of the 24th ACM SIGKDD International Conference (Confidence: 0.99)\n",
            "Detected text: on Knowfedge Discovery &#38; Data Mining, ser. KDD 18.New (Confidence: 0.97)\n",
            "Detected text: Category (Confidence: 1.00)\n",
            "Detected text: Method (Confidence: 1.00)\n",
            "Detected text: Initialization (Confidence: 1.00)\n",
            "Detected text: F-RCNN (Confidence: 1.00)\n",
            "Detected text: M-RCNN (Confidence: 1.00)\n",
            "Detected text: http://doi.acm.org/10.1145/3219819.3219834 (Confidence: 1.00)\n",
            "Detected text: zero-shot (Confidence: 1.00)\n",
            "Detected text: PubLayNet (Confidence: 0.95)\n",
            "Detected text: 0.482 (Confidence: 1.00)\n",
            "Detected text: 0.468 (Confidence: 1.00)\n",
            "Detected text: [2] R. Cattoni, T. Coianiz, S. Messelodi, and C. M. Modena, Geometric (Confidence: 0.99)\n",
            "Detected text: Text (Confidence: 0.89)\n",
            "Detected text: fine tuning (Confidence: 0.95)\n",
            "Detected text: PubLayNet (Confidence: 1.00)\n",
            "Detected text: 0.701 (Confidence: 0.94)\n",
            "Detected text: 0.708 (Confidence: 0.90)\n",
            "Detected text: layout analysis techniques for document image understanding: a review, (Confidence: 0.98)\n",
            "Detected text: fine tuning (Confidence: 1.00)\n",
            "Detected text: COCO (Confidence: 0.98)\n",
            "Detected text: 0.622 (Confidence: 1.00)\n",
            "Detected text: 0.651 (Confidence: 1.00)\n",
            "Detected text: 0.661 (Confidence: 1.00)\n",
            "Detected text: [3] T. M. Breuel, Two geometric algorithms for layout analysis, in (Confidence: 0.99)\n",
            "Detected text: ITC-irst Technical Report, vol. 9703, no. 09, 1998. (Confidence: 0.99)\n",
            "Detected text: fine tuning (Confidence: 1.00)\n",
            "Detected text: ImageNet (Confidence: 1.00)\n",
            "Detected text: 0.629 (Confidence: 1.00)\n",
            "Detected text: zero-shot (Confidence: 1.00)\n",
            "Detected text: PubLayNet (Confidence: 0.95)\n",
            "Detected text: 0.508 (Confidence: 1.00)\n",
            "Detected text: 0.510 (Confidence: 1.00)\n",
            "Detected text: International workshop on document analysis systems. Springer, 2002, (Confidence: 0.99)\n",
            "Detected text: fine tuning (Confidence: 0.99)\n",
            "Detected text: PubLayNet (Confidence: 1.00)\n",
            "Detected text: 0.681 (Confidence: 0.97)\n",
            "Detected text: 0.684 (Confidence: 0.99)\n",
            "Detected text: pp. 188199. (Confidence: 0.97)\n",
            "Detected text: List (Confidence: 1.00)\n",
            "Detected text: fine tuning (Confidence: 0.95)\n",
            "Detected text: COCO (Confidence: 0.98)\n",
            "Detected text: 0.622 (Confidence: 1.00)\n",
            "Detected text: 0.611 (Confidence: 1.00)\n",
            "Detected text: [4 (Confidence: 0.78)\n",
            "Detected text: the Symposiam on Document Image Understanding Technology, 2003, (Confidence: 0.97)\n",
            "Detected text: High performance document layout analysis, in Proceedings of (Confidence: 0.99)\n",
            "Detected text: fine tuning (Confidence: 1.00)\n",
            "Detected text: ImageNet (Confidence: 1.00)\n",
            "Detected text: 0.603 (Confidence: 0.94)\n",
            "Detected text: 0.603 (Confidence: 0.90)\n",
            "Detected text: K. He, G. Gkioxari, P. Dollar, and R. Girshick, Mask r-cnn, in (Confidence: 0.98)\n",
            "Detected text: pp. 209218. (Confidence: 0.95)\n",
            "Detected text: zero-shot (Confidence: 1.00)\n",
            "Detected text: PubLayNet (Confidence: 0.95)\n",
            "Detected text: 0.422 (Confidence: 1.00)\n",
            "Detected text: 0.541 (Confidence: 0.99)\n",
            "Detected text: 0.419 (Confidence: 0.93)\n",
            "Detected text: [5] (Confidence: 0.78)\n",
            "Detected text: fine tuning (Confidence: 1.00)\n",
            "Detected text: 0.596 (Confidence: 1.00)\n",
            "Detected text: Table (Confidence: 1.00)\n",
            "Detected text: PubLayNet (Confidence: 1.00)\n",
            "Detected text: Computer Vision (ICCV), 2017 IEEE International Conference on. (Confidence: 0.98)\n",
            "Detected text: fine tuning (Confidence: 1.00)\n",
            "Detected text: 0.560 (Confidence: 1.00)\n",
            "Detected text: 0.588 (Confidence: 1.00)\n",
            "Detected text: IEEE, 2017, pp. 29802988. (Confidence: 1.00)\n",
            "Detected text: fine tuning (Confidence: 1.00)\n",
            "Detected text: ImageNet (Confidence: 1.00)\n",
            "Detected text: 0.528 (Confidence: 1.00)\n",
            "Detected text: 0.573 (Confidence: 1.00)\n",
            "Detected text: [6] S. Schreiber, S. Agne, I. Wolf, A. Dengel, and S. Ahmed, Deepdesrt: (Confidence: 0.98)\n",
            "Detected text: 0.465 (Confidence: 1.00)\n",
            "Detected text: Deep learning for detection and structure recognition of tables in (Confidence: 0.98)\n",
            "Detected text: zero-shot (Confidence: 0.99)\n",
            "Detected text: PubLayNet (Confidence: 1.00)\n",
            "Detected text: PubLayNet (Confidence: 1.00)\n",
            "Detected text: 0.470 (Confidence: 0.93)\n",
            "Detected text: fine tuning (Confidence: 0.99)\n",
            "Detected text: 0.641 (Confidence: 0.91)\n",
            "Detected text: 0.663 (Confidence: 0.99)\n",
            "Detected text: 2017 14th IAPR International Conference on, vol. 1. IEEE, 2017, pp. (Confidence: 0.97)\n",
            "Detected text: document images,\" in Document Analysis and Recognition (ICDAR), (Confidence: 0.98)\n",
            "Detected text: Macro (Confidence: 1.00)\n",
            "Detected text: average (Confidence: 1.00)\n",
            "Detected text: fine tuning (Confidence: 1.00)\n",
            "Detected text: fine tuning (Confidence: 1.00)\n",
            "Detected text: 0.611 (Confidence: 1.00)\n",
            "Detected text: 0.620 (Confidence: 1.00)\n",
            "Detected text: ImageNet (Confidence: 1.00)\n",
            "Detected text: 0.584 (Confidence: 1.00)\n",
            "Detected text: 0.602 (Confidence: 1.00)\n",
            "Detected text: [7] A. Antonacopoulos, D. Bridson, C. Papadopoulos, and S. Pletschacher, (Confidence: 0.98)\n",
            "Detected text: 11621167. (Confidence: 1.00)\n",
            "Detected text: A realistic dataset for performance evaluation of document layout (Confidence: 0.98)\n",
            "Detected text: analysis, in Document Analysis and Recognition, 2009. ICDAR09. 10th (Confidence: 0.98)\n",
            "Detected text: International Conference on.. (Confidence: 0.97)\n",
            "Detected text: IEEE, 2009, pp. 296300. (Confidence: 0.97)\n",
            "Detected text: to train deep learning models that can accurately recognize (Confidence: 1.00)\n",
            "Detected text: [8] C. Clausner, C. Papadopoulos, S. Pletschacher, and A. Antonacopoulos, (Confidence: 0.99)\n",
            "Detected text: the layout of unseen journals. For documents in a distant (Confidence: 0.99)\n",
            "Detected text: domain, e.g., government documents and SPD documents, (Confidence: 0.99)\n",
            "Detected text: Docunent Analysis and Recognition (ICDAR), 2015 13th International (Confidence: 0.98)\n",
            "Detected text: Conference on. (Confidence: 1.00)\n",
            "Detected text: IEEE, 2015, pp. 931935. (Confidence: 0.99)\n",
            "Detected text: we demonstrated the value of using PubLayNet in a transfer (Confidence: 1.00)\n",
            "Detected text: [9] C. Clausner, A. Antonacopoulos, and S. Pletschacher, Icdar2017 (Confidence: 0.96)\n",
            "Detected text: learning setting. (Confidence: 1.00)\n",
            "Detected text: complex (Confidence: 0.96)\n",
            "Detected text: layouts-rdcl2017, in Docunent Analysis and Recognition (ICDAR), (Confidence: 0.98)\n",
            "Detected text: VI. CONCLUSION (Confidence: 0.99)\n",
            "Detected text: 2017 14th IAPR Intenational Conference on, vol. 1. IEEE, 2017, pp. (Confidence: 0.99)\n",
            "Detected text: 14041410. (Confidence: 1.00)\n",
            "Detected text: We automatically generated the PubLayNet dataset, which (Confidence: 0.98)\n",
            "Detected text: [10] A. Shahab, F. Shafait, T. Kieninger, and A. Dengel, An open approach (Confidence: 0.99)\n",
            "Detected text: towards the benchmarking of table structure recognition systems, in (Confidence: 0.99)\n",
            "Detected text: is the largest ever available document layout annotation (Confidence: 0.99)\n",
            "Detected text: Proceedings of the 9th IAPR International Workshop on Document (Confidence: 0.97)\n",
            "Detected text: dataset exploiting redundancy in PCMOA. This dataset allows (Confidence: 1.00)\n",
            "Detected text: [11] J. Fang, X. Tao, Z. Tang, R. Qiu, and Y. Liu, Dataset, ground-truth (Confidence: 0.98)\n",
            "Detected text: Analysis Systems.ACM, 2010, pp. 113120. (Confidence: 0.99)\n",
            "Detected text: state-of-the-art object detection algorithms to be trained (Confidence: 0.98)\n",
            "Detected text: and performance metrics for table detection evaluation, in Documenr (Confidence: 0.95)\n",
            "Detected text: delivering high performance layout recognition on biomedical (Confidence: 0.99)\n",
            "Detected text: Analysis Systems (DAS), 2012 10th IAPR Internationa! Workshop on. (Confidence: 0.98)\n",
            "Detected text: articles. Furthermore, this dataset is shown to be helpful (Confidence: 0.99)\n",
            "Detected text: IEEE, 2012, pp. 445449. (Confidence: 1.00)\n",
            "Detected text: to pre-train object detection algorithms to identify tables (Confidence: 0.99)\n",
            "Detected text: [12] B. Yildiz, K. Kaiser, and S. Miksch, pdf2table: A method to extract (Confidence: 0.99)\n",
            "Detected text: and different document layout objects in health insurance (Confidence: 0.99)\n",
            "Detected text: table information from pdf files, in IICA/, 2005, pp. 17731785. (Confidence: 0.97)\n",
            "Detected text: [13] D. N. Tran, T. A. Tran, A. Oh, S. H. Kim, and I. S. Na, Table (Confidence: 0.98)\n",
            "Detected text: documents. These results are encouraging since the developed (Confidence: 0.99)\n",
            "Detected text: blocks, International Jounal of Contents, vol. 11, no. 4, pp. 7785, (Confidence: 0.98)\n",
            "Detected text: dataset is potentially helpful for document layout annotation (Confidence: 1.00)\n",
            "Detected text: 2015. (Confidence: 1.00)\n",
            "Detected text: of other domains. PubLayNet is available from https:/github. (Confidence: 1.00)\n",
            "Detected text: [14] D. He, S. Cohen, B. Price, D. Kifer, and C. L. Giles, Multi-scale (Confidence: 0.98)\n",
            "Detected text: com/ibm-aur-nlp/PubLayNet. (Confidence: 1.00)\n",
            "Detected text: multi-task fcn for semantic page segmentation and table detection, (Confidence: 0.98)\n",
            "Detected text: As future work, we plan to exploit PMCOA for the (Confidence: 0.96)\n",
            "Detected text: in Document Analysis and Recognition (ICDAR), 2017 I4th IAPR (Confidence: 0.97)\n",
            "Detected text: International Conference on, vol. 1.IEEE, 2017, pp. 254261. (Confidence: 0.99)\n",
            "Detected text: automatic generation of large datasets to solve other document (Confidence: 0.99)\n",
            "Detected text: [15] L. Hao, L. Gao, X. Yi, and Z. Tang, A table detection method for (Confidence: 0.98)\n",
            "Detected text: analysis problems with deep learning models. For example, (Confidence: 1.00)\n",
            "Detected text: pdf documents based on convolutional neural networks, in Docanenr (Confidence: 0.96)\n",
            "Detected text: PubLayNet does not contain relationships between the (Confidence: 0.98)\n",
            "Detected text: Analysis Systems (DAS), 2016 I2th IAPR Workshop on. (Confidence: 0.97)\n",
            "Detected text: IEEE, 2016 (Confidence: 1.00)\n",
            "Detected text: [16] (Confidence: 0.86)\n",
            "Detected text: pp. 287292. (Confidence: 0.93)\n",
            "Detected text: layout elements, e.g., a paragraph and a section title. Such (Confidence: 0.99)\n",
            "Detected text: A. Gilani, S. R. Qasim, I. Malik, and F. Shafait, Table detection (Confidence: 0.98)\n",
            "Detected text: information is available in the XML representation and can be (Confidence: 0.99)\n",
            "Detected text: using deep learning, in 2017 I4th IAPR International Conference on (Confidence: 0.97)\n",
            "Detected text: exploit to automatically create a dataset of the logical structure (Confidence: 0.99)\n",
            "Detected text: Docunent Analysis and Recognition (ICDAR), vol. 01, Nov 2017, pp. (Confidence: 0.98)\n",
            "Detected text: 771776. (Confidence: 0.98)\n",
            "Detected text: of documents. (Confidence: 1.00)\n",
            "Detected text: [17] I. Kavasidis, S. Palazzo, C. Spampinato, C. Pino, D.Giordano, (Confidence: 0.97)\n",
            "Detected text: D. Giuffrida, and P. Messina, A saliency-based convolutional neural (Confidence: 0.99)\n",
            "Detected text: ACKNOWLEDGMENT (Confidence: 1.00)\n",
            "Detected text: network for table and chart detection in digitized documents,\" arXiv (Confidence: 0.98)\n",
            "Detected text: preprint arXiv:1804.06236, 2018. (Confidence: 0.99)\n",
            "Detected text: We thank Manoj Gambhir for relevant feedback on this (Confidence: 0.99)\n",
            "Detected text: [18] V. I. Levenshtein, Binary codes capable of correcting deletions (Confidence: 0.98)\n",
            "Detected text: insertions, and reversals, in Sovier physics doklady, vol. 10, no. 8, 1966, (Confidence: 0.99)\n",
            "Detected text: work and for his work in the development of the SPD data (Confidence: 0.99)\n",
            "Detected text: pp. 707710. (Confidence: 0.95)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Provide the path to your table image\n",
        "image_path = \"/content/scientific-table.jpg\"\n",
        "\n",
        "# Extract detected text with positions\n",
        "data = []\n",
        "for line in result:\n",
        "    for word_info in line:\n",
        "        text, confidence, position = word_info[1][0], word_info[1][1], word_info[0]\n",
        "        x_min = min([coord[0] for coord in position])  # Get left-most X coordinate\n",
        "        y_min = min([coord[1] for coord in position])  # Get top-most Y coordinate\n",
        "        data.append((text, confidence, x_min, y_min))\n",
        "\n",
        "# Sort by Y first (rows), then X (columns)\n",
        "data.sort(key=lambda x: (x[3], x[2]))\n",
        "\n",
        "# Convert to a DataFrame (assuming a rough column structure)\n",
        "df = pd.DataFrame([row[:2] for row in data], columns=[\"Text\", \"Confidence\"])\n",
        "\n",
        "# Print as table\n",
        "print(df.to_markdown())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nkqXvbUWZEy",
        "outputId": "e1cddcde-1bf1-4b77-9abb-46de6932b601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|     | Text                                                                        |   Confidence |\n",
            "|----:|:----------------------------------------------------------------------------|-------------:|\n",
            "|   0 | TABLE V: Comparison of the performance of fine tuning                       |     0.987456 |\n",
            "|   1 | set and Shaila Pervin for her work in the development of the                |     0.999914 |\n",
            "|   2 | different pre-trained F-RCNN and M-RCNN models on the                       |     0.99158  |\n",
            "|   3 | SPD data set.                                                               |     0.999452 |\n",
            "|   4 | SPD documents. The performance scores are MAP @ IOU                         |     0.985415 |\n",
            "|   5 | [0.50:0.95] evaluated via a 5-fold cross-document-validation                |     0.993534 |\n",
            "|   6 | REFERENCES                                                                  |     0.998755 |\n",
            "|   7 | on 20 SPD documents. The results demonstrate the advantage                  |     0.993442 |\n",
            "|   8 | [1] P. W. J. Staar, M. Dolfi., C. Auer, and C. Bekas, Corpus conversion     |     0.979452 |\n",
            "|   9 | of PubLayNet over general image datasets in domain                          |     0.964122 |\n",
            "|  10 | service: A machine learning platform to ingest documents at scale,          |     0.974165 |\n",
            "|  11 | in Proceedings of the 24th ACM SIGKDD International Conference              |     0.987825 |\n",
            "|  12 | adaptation for document layout analysis.                                    |     0.988972 |\n",
            "|  13 | on Knowfedge Discovery &#38; Data Mining, ser. KDD 18.New                   |     0.967341 |\n",
            "|  14 | M-RCNN                                                                      |     0.998989 |\n",
            "|  15 | Category                                                                    |     0.999903 |\n",
            "|  16 | Method                                                                      |     0.999858 |\n",
            "|  17 | Initialization                                                              |     0.99996  |\n",
            "|  18 | F-RCNN                                                                      |     0.999293 |\n",
            "|  19 | http://doi.acm.org/10.1145/3219819.3219834                                  |     0.999249 |\n",
            "|  20 | PubLayNet                                                                   |     0.948439 |\n",
            "|  21 | [2] R. Cattoni, T. Coianiz, S. Messelodi, and C. M. Modena, Geometric       |     0.98688  |\n",
            "|  22 | 0.482                                                                       |     0.999887 |\n",
            "|  23 | 0.468                                                                       |     0.999788 |\n",
            "|  24 | zero-shot                                                                   |     0.996042 |\n",
            "|  25 | fine tuning                                                                 |     0.951832 |\n",
            "|  26 | PubLayNet                                                                   |     0.999866 |\n",
            "|  27 | layout analysis techniques for document image understanding: a review,      |     0.978936 |\n",
            "|  28 | 0.701                                                                       |     0.939555 |\n",
            "|  29 | 0.708                                                                       |     0.900187 |\n",
            "|  30 | Text                                                                        |     0.889449 |\n",
            "|  31 | fine tuning                                                                 |     0.99749  |\n",
            "|  32 | COCO                                                                        |     0.976737 |\n",
            "|  33 | 0.651                                                                       |     0.999787 |\n",
            "|  34 | 0.661                                                                       |     0.999849 |\n",
            "|  35 | ITC-irst Technical Report, vol. 9703, no. 09, 1998.                         |     0.988106 |\n",
            "|  36 | 0.622                                                                       |     0.997712 |\n",
            "|  37 | [3] T. M. Breuel, Two geometric algorithms for layout analysis, in          |     0.988794 |\n",
            "|  38 | ImageNet                                                                    |     0.999934 |\n",
            "|  39 | 0.629                                                                       |     0.999882 |\n",
            "|  40 | fine tuning                                                                 |     0.999917 |\n",
            "|  41 | International workshop on document analysis systems. Springer, 2002,        |     0.985515 |\n",
            "|  42 | PubLayNet                                                                   |     0.948439 |\n",
            "|  43 | 0.510                                                                       |     0.999116 |\n",
            "|  44 | 0.508                                                                       |     0.999821 |\n",
            "|  45 | zero-shot                                                                   |     0.998633 |\n",
            "|  46 | pp. 188199.                                                                 |     0.968847 |\n",
            "|  47 | fine tuning                                                                 |     0.985732 |\n",
            "|  48 | 0.681                                                                       |     0.97494  |\n",
            "|  49 | 0.684                                                                       |     0.988282 |\n",
            "|  50 | PubLayNet                                                                   |     0.998464 |\n",
            "|  51 | High performance document layout analysis, in Proceedings of                |     0.992075 |\n",
            "|  52 | List                                                                        |     0.999854 |\n",
            "|  53 | [4                                                                          |     0.78001  |\n",
            "|  54 | fine tuning                                                                 |     0.945961 |\n",
            "|  55 | COCO                                                                        |     0.983286 |\n",
            "|  56 | 0.622                                                                       |     0.999832 |\n",
            "|  57 | 0.611                                                                       |     0.999824 |\n",
            "|  58 | the Symposiam on Document Image Understanding Technology, 2003,             |     0.967534 |\n",
            "|  59 | fine tuning                                                                 |     0.999815 |\n",
            "|  60 | 0.603                                                                       |     0.937576 |\n",
            "|  61 | 0.603                                                                       |     0.903863 |\n",
            "|  62 | ImageNet                                                                    |     0.999937 |\n",
            "|  63 | pp. 209218.                                                                 |     0.948904 |\n",
            "|  64 | K. He, G. Gkioxari, P. Dollar, and R. Girshick, Mask r-cnn, in              |     0.978289 |\n",
            "|  65 | PubLayNet                                                                   |     0.948439 |\n",
            "|  66 | 0.422                                                                       |     0.999217 |\n",
            "|  67 | 0.419                                                                       |     0.932545 |\n",
            "|  68 | [5]                                                                         |     0.782427 |\n",
            "|  69 | zero-shot                                                                   |     0.998633 |\n",
            "|  70 | 0.541                                                                       |     0.989914 |\n",
            "|  71 | Computer Vision (ICCV), 2017 IEEE International Conference on.              |     0.981542 |\n",
            "|  72 | fine tuning                                                                 |     0.999847 |\n",
            "|  73 | 0.596                                                                       |     0.999045 |\n",
            "|  74 | PubLayNet                                                                   |     0.998464 |\n",
            "|  75 | Table                                                                       |     0.999944 |\n",
            "|  76 | IEEE, 2017, pp. 29802988.                                                   |     0.999142 |\n",
            "|  77 | fine tuning                                                                 |     0.99861  |\n",
            "|  78 | 0.560                                                                       |     0.996949 |\n",
            "|  79 | 0.588                                                                       |     0.999916 |\n",
            "|  80 | [6] S. Schreiber, S. Agne, I. Wolf, A. Dengel, and S. Ahmed, Deepdesrt:     |     0.981339 |\n",
            "|  81 | 0.528                                                                       |     0.999822 |\n",
            "|  82 | 0.573                                                                       |     0.999864 |\n",
            "|  83 | fine tuning                                                                 |     0.999928 |\n",
            "|  84 | ImageNet                                                                    |     0.999969 |\n",
            "|  85 | Deep learning for detection and structure recognition of tables in          |     0.976146 |\n",
            "|  86 | 0.465                                                                       |     0.998961 |\n",
            "|  87 | zero-shot                                                                   |     0.990018 |\n",
            "|  88 | PubLayNet                                                                   |     0.999902 |\n",
            "|  89 | 0.470                                                                       |     0.933874 |\n",
            "|  90 | document images,\" in Document Analysis and Recognition (ICDAR),             |     0.977873 |\n",
            "|  91 | PubLayNet                                                                   |     0.999794 |\n",
            "|  92 | fine tuning                                                                 |     0.990418 |\n",
            "|  93 | 0.641                                                                       |     0.911004 |\n",
            "|  94 | 0.663                                                                       |     0.992569 |\n",
            "|  95 | 2017 14th IAPR International Conference on, vol. 1. IEEE, 2017, pp.         |     0.970495 |\n",
            "|  96 | Macro                                                                       |     0.999766 |\n",
            "|  97 | fine tuning                                                                 |     0.99876  |\n",
            "|  98 | 0.611                                                                       |     0.999818 |\n",
            "|  99 | 0.620                                                                       |     0.999851 |\n",
            "| 100 | average                                                                     |     0.999767 |\n",
            "| 101 | 11621167.                                                                   |     0.999914 |\n",
            "| 102 | fine tuning                                                                 |     0.998745 |\n",
            "| 103 | 0.584                                                                       |     0.999818 |\n",
            "| 104 | 0.602                                                                       |     0.999782 |\n",
            "| 105 | ImageNet                                                                    |     0.999969 |\n",
            "| 106 | [7] A. Antonacopoulos, D. Bridson, C. Papadopoulos, and S. Pletschacher,    |     0.980705 |\n",
            "| 107 | A realistic dataset for performance evaluation of document layout           |     0.979999 |\n",
            "| 108 | analysis, in Document Analysis and Recognition, 2009. ICDAR09. 10th         |     0.982979 |\n",
            "| 109 | IEEE, 2009, pp. 296300.                                                     |     0.974402 |\n",
            "| 110 | International Conference on..                                               |     0.971037 |\n",
            "| 111 | to train deep learning models that can accurately recognize                 |     0.997435 |\n",
            "| 112 | [8] C. Clausner, C. Papadopoulos, S. Pletschacher, and A. Antonacopoulos,   |     0.991999 |\n",
            "| 113 | the layout of unseen journals. For documents in a distant                   |     0.991397 |\n",
            "| 114 | Docunent Analysis and Recognition (ICDAR), 2015 13th International          |     0.97844  |\n",
            "| 115 | domain, e.g., government documents and SPD documents,                       |     0.994842 |\n",
            "| 116 | IEEE, 2015, pp. 931935.                                                     |     0.988445 |\n",
            "| 117 | Conference on.                                                              |     0.99793  |\n",
            "| 118 | we demonstrated the value of using PubLayNet in a transfer                  |     0.999842 |\n",
            "| 119 | [9] C. Clausner, A. Antonacopoulos, and S. Pletschacher, Icdar2017          |     0.958876 |\n",
            "| 120 | complex                                                                     |     0.962872 |\n",
            "| 121 | learning setting.                                                           |     0.998063 |\n",
            "| 122 | layouts-rdcl2017, in Docunent Analysis and Recognition (ICDAR),             |     0.980941 |\n",
            "| 123 | 2017 14th IAPR Intenational Conference on, vol. 1. IEEE, 2017, pp.          |     0.985142 |\n",
            "| 124 | VI. CONCLUSION                                                              |     0.988629 |\n",
            "| 125 | 14041410.                                                                   |     0.999923 |\n",
            "| 126 | [10] A. Shahab, F. Shafait, T. Kieninger, and A. Dengel, An open approach   |     0.992147 |\n",
            "| 127 | We automatically generated the PubLayNet dataset, which                     |     0.981921 |\n",
            "| 128 | towards the benchmarking of table structure recognition systems, in         |     0.990868 |\n",
            "| 129 | is the largest ever available document layout annotation                    |     0.992239 |\n",
            "| 130 | Proceedings of the 9th IAPR International Workshop on Document              |     0.974186 |\n",
            "| 131 | Analysis Systems.ACM, 2010, pp. 113120.                                     |     0.990663 |\n",
            "| 132 | dataset exploiting redundancy in PCMOA. This dataset allows                 |     0.999394 |\n",
            "| 133 | [11] J. Fang, X. Tao, Z. Tang, R. Qiu, and Y. Liu, Dataset, ground-truth    |     0.982557 |\n",
            "| 134 | state-of-the-art object detection algorithms to be trained                  |     0.978316 |\n",
            "| 135 | and performance metrics for table detection evaluation, in Documenr         |     0.953691 |\n",
            "| 136 | delivering high performance layout recognition on biomedical                |     0.993049 |\n",
            "| 137 | Analysis Systems (DAS), 2012 10th IAPR Internationa! Workshop on.           |     0.982572 |\n",
            "| 138 | IEEE, 2012, pp. 445449.                                                     |     0.99962  |\n",
            "| 139 | articles. Furthermore, this dataset is shown to be helpful                  |     0.992559 |\n",
            "| 140 | [12] B. Yildiz, K. Kaiser, and S. Miksch, pdf2table: A method to extract    |     0.992814 |\n",
            "| 141 | to pre-train object detection algorithms to identify tables                 |     0.988777 |\n",
            "| 142 | table information from pdf files, in IICA/, 2005, pp. 17731785.             |     0.973903 |\n",
            "| 143 | and different document layout objects in health insurance                   |     0.990173 |\n",
            "| 144 | [13] D. N. Tran, T. A. Tran, A. Oh, S. H. Kim, and I. S. Na, Table          |     0.97613  |\n",
            "| 145 | documents. These results are encouraging since the developed                |     0.988605 |\n",
            "| 146 | blocks, International Jounal of Contents, vol. 11, no. 4, pp. 7785,         |     0.983331 |\n",
            "| 147 | dataset is potentially helpful for document layout annotation               |     0.99871  |\n",
            "| 148 | 2015.                                                                       |     0.998619 |\n",
            "| 149 | of other domains. PubLayNet is available from https:/github.                |     0.996227 |\n",
            "| 150 | [14] D. He, S. Cohen, B. Price, D. Kifer, and C. L. Giles, Multi-scale      |     0.984037 |\n",
            "| 151 | multi-task fcn for semantic page segmentation and table detection,          |     0.982356 |\n",
            "| 152 | com/ibm-aur-nlp/PubLayNet.                                                  |     0.997444 |\n",
            "| 153 | in Document Analysis and Recognition (ICDAR), 2017 I4th IAPR                |     0.972776 |\n",
            "| 154 | As future work, we plan to exploit PMCOA for the                            |     0.959343 |\n",
            "| 155 | International Conference on, vol. 1.IEEE, 2017, pp. 254261.                 |     0.989938 |\n",
            "| 156 | [15] L. Hao, L. Gao, X. Yi, and Z. Tang, A table detection method for       |     0.976936 |\n",
            "| 157 | automatic generation of large datasets to solve other document              |     0.992254 |\n",
            "| 158 | pdf documents based on convolutional neural networks, in Docanenr           |     0.963058 |\n",
            "| 159 | analysis problems with deep learning models. For example,                   |     0.996919 |\n",
            "| 160 | Analysis Systems (DAS), 2016 I2th IAPR Workshop on.                         |     0.974086 |\n",
            "| 161 | IEEE, 2016                                                                  |     0.998998 |\n",
            "| 162 | PubLayNet does not contain relationships between the                        |     0.97987  |\n",
            "| 163 | pp. 287292.                                                                 |     0.933794 |\n",
            "| 164 | [16]                                                                        |     0.864422 |\n",
            "| 165 | A. Gilani, S. R. Qasim, I. Malik, and F. Shafait, Table detection           |     0.976572 |\n",
            "| 166 | layout elements, e.g., a paragraph and a section title. Such                |     0.994624 |\n",
            "| 167 | using deep learning, in 2017 I4th IAPR International Conference on          |     0.969345 |\n",
            "| 168 | information is available in the XML representation and can be               |     0.991168 |\n",
            "| 169 | Docunent Analysis and Recognition (ICDAR), vol. 01, Nov 2017, pp.           |     0.976287 |\n",
            "| 170 | exploit to automatically create a dataset of the logical structure          |     0.985132 |\n",
            "| 171 | 771776.                                                                     |     0.984445 |\n",
            "| 172 | [17] I. Kavasidis, S. Palazzo, C. Spampinato, C. Pino, D.Giordano,          |     0.96684  |\n",
            "| 173 | of documents.                                                               |     0.999471 |\n",
            "| 174 | D. Giuffrida, and P. Messina, A saliency-based convolutional neural         |     0.990191 |\n",
            "| 175 | network for table and chart detection in digitized documents,\" arXiv        |     0.978571 |\n",
            "| 176 | ACKNOWLEDGMENT                                                              |     0.999676 |\n",
            "| 177 | preprint arXiv:1804.06236, 2018.                                            |     0.993509 |\n",
            "| 178 | [18] V. I. Levenshtein, Binary codes capable of correcting deletions        |     0.981724 |\n",
            "| 179 | We thank Manoj Gambhir for relevant feedback on this                        |     0.988255 |\n",
            "| 180 | insertions, and reversals, in Sovier physics doklady, vol. 10, no. 8, 1966, |     0.989781 |\n",
            "| 181 | pp. 707710.                                                                 |     0.948143 |\n",
            "| 182 | work and for his work in the development of the SPD data                    |     0.991079 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Provide image path\n",
        "image_path = \"/content/scientific-table.jpg\"\n",
        "\n",
        "# Run OCR\n",
        "result = ocr_model.ocr(image_path, cls=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM3ECEtfXyCq",
        "outputId": "698497ae-0a72-4ecf-864c-43d70805bfff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025/03/02 19:39:32] ppocr DEBUG: dt_boxes num : 23, elapsed : 0.15179181098937988\n",
            "[2025/03/02 19:39:32] ppocr DEBUG: cls num  : 23, elapsed : 0.08382678031921387\n",
            "[2025/03/02 19:39:34] ppocr DEBUG: rec_res num  : 23, elapsed : 1.8494350910186768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract text and positions\n",
        "table_data = []\n",
        "for line in result:\n",
        "    row_data = []\n",
        "    for word_info in line:\n",
        "        text, confidence = word_info[1][0], word_info[1][1]\n",
        "        row_data.append(text)\n",
        "    table_data.append(row_data)\n"
      ],
      "metadata": {
        "id": "ypv-DOFhXz3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(table_data)\n",
        "\n",
        "# Print as table using PrettyTable\n",
        "table = PrettyTable()\n",
        "table.field_names = [\"Column \" + str(i+1) for i in range(len(df.columns))]  # Auto-generate column names\n",
        "for row in df.values:\n",
        "    table.add_row(row)\n",
        "\n",
        "print(table)  # Show table in terminal\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrN9saxvX3yH",
        "outputId": "8b58b06a-54f8-46fe-f9ca-beaf17a1f9c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------------------------------------------+----------+----------+----------+----------+----------+----------+----------+----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+\n",
            "|                             Column 1                            | Column 2 | Column 3 | Column 4 | Column 5 | Column 6 | Column 7 | Column 8 | Column 9 | Column 10 | Column 11 | Column 12 | Column 13 | Column 14 | Column 15 | Column 16 | Column 17 | Column 18 | Column 19 | Column 20 | Column 21 | Column 22 |\n",
            "+-----------------------------------------------------------------+----------+----------+----------+----------+----------+----------+----------+----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+\n",
            "| Table 1.Exposure to salinity reduces the growth of wheat plants |  Group   |  light   |  5days   | 10 days  | control  |    12    |  70.32   |  9010.5  |    test   |     12    |  60.41.5* |   787.9*  |  control  |     16    |   75.78.  |    1003   |    test   |     16    |   52.22   |   816.7   |  *P<0.05. |\n",
            "+-----------------------------------------------------------------+----------+----------+----------+----------+----------+----------+----------+----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from paddleocr import PaddleOCR\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "# Initialize PaddleOCR for English text recognition\n",
        "ocr_model = PaddleOCR(use_angle_cls=True, lang=\"en\")\n",
        "\n",
        "# Provide the path to your table image\n",
        "image_path = \"/content/scientific-table.jpg\"\n",
        "\n",
        "# Ensure the image exists before processing\n",
        "if not os.path.exists(image_path):\n",
        "    print(f\"Error: Image not found at {image_path}\")\n",
        "else:\n",
        "    # Run OCR on the image\n",
        "    result = ocr_model.ocr(image_path, cls=True)\n",
        "\n",
        "    # Extract detected text with positions\n",
        "    data = []\n",
        "    for line in result:\n",
        "        for word_info in line:\n",
        "            text, confidence, position = word_info[1][0], word_info[1][1], word_info[0]\n",
        "            x_min = min([coord[0] for coord in position])  # Get left-most X coordinate\n",
        "            y_min = min([coord[1] for coord in position])  # Get top-most Y coordinate\n",
        "            data.append((text, confidence, x_min, y_min))\n",
        "\n",
        "    # Sort data: First by Y (rows), then by X (columns)\n",
        "    data.sort(key=lambda x: (x[3], x[2]))\n",
        "\n",
        "    # Group words into rows (assuming words on the same Y level are in the same row)\n",
        "    rows = []\n",
        "    current_row = []\n",
        "    current_y = None\n",
        "    threshold = 10  # Adjust this to fine-tune row grouping\n",
        "\n",
        "    for word, confidence, x, y in data:\n",
        "        if current_y is None or abs(y - current_y) < threshold:\n",
        "            current_row.append(word)\n",
        "        else:\n",
        "            rows.append(current_row)\n",
        "            current_row = [word]\n",
        "        current_y = y\n",
        "\n",
        "    if current_row:\n",
        "        rows.append(current_row)\n",
        "\n",
        "    # Convert rows into a Pandas DataFrame\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    # Print as PrettyTable\n",
        "    table = PrettyTable()\n",
        "    table.field_names = [f\"Column {i+1}\" for i in range(df.shape[1])]  # Auto-generate column names\n",
        "\n",
        "    for row in df.values:\n",
        "        table.add_row(row)\n",
        "\n",
        "    print(\"\\n**Detected Table:**\")\n",
        "    print(table)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12fTLcNMZ7xl",
        "outputId": "1c33b18e-ee3d-48a4-9c6f-2723104ac8a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025/03/02 19:49:09] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/root/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/usr/local/lib/python3.11/dist-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
            "[2025/03/02 19:49:10] ppocr DEBUG: dt_boxes num : 23, elapsed : 0.12497210502624512\n",
            "[2025/03/02 19:49:11] ppocr DEBUG: cls num  : 23, elapsed : 0.6910784244537354\n",
            "[2025/03/02 19:49:13] ppocr DEBUG: rec_res num  : 23, elapsed : 2.419888734817505\n",
            "\n",
            "**Detected Table:**\n",
            "+-----------------------------------------------------------------+----------+----------+----------+\n",
            "|                             Column 1                            | Column 2 | Column 3 | Column 4 |\n",
            "+-----------------------------------------------------------------+----------+----------+----------+\n",
            "| Table 1.Exposure to salinity reduces the growth of wheat plants |   None   |   None   |   None   |\n",
            "|                              5days                              | 10 days  |  Group   |  light   |\n",
            "|                                12                               | control  |  70.32   |  9010.5  |\n",
            "|                             60.41.5*                            |  787.9*  |    12    |   test   |\n",
            "|                              75.78.                             | control  |    16    |   1003   |\n",
            "|                              52.22                              |  816.7   |    16    |   test   |\n",
            "|                             *P<0.05.                            |   None   |   None   |   None   |\n",
            "+-----------------------------------------------------------------+----------+----------+----------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from paddleocr import PaddleOCR\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "# Initialize PaddleOCR for English text recognition\n",
        "ocr_model = PaddleOCR(use_angle_cls=True, lang=\"en\")\n",
        "\n",
        "# Provide the path to your table image\n",
        "image_path = \"/content/scientific-table.jpg\"\n",
        "\n",
        "# Ensure the image exists before processing\n",
        "if not os.path.exists(image_path):\n",
        "    print(f\"Error: Image not found at {image_path}\")\n",
        "else:\n",
        "    # Run OCR on the image\n",
        "    result = ocr_model.ocr(image_path, cls=True)\n",
        "\n",
        "    # Extract detected text with positions\n",
        "    data = []\n",
        "    for line in result:\n",
        "        for word_info in line:\n",
        "            text, confidence, position = word_info[1][0], word_info[1][1], word_info[0]\n",
        "            x_min = min([coord[0] for coord in position])  # Get left-most X coordinate\n",
        "            y_min = min([coord[1] for coord in position])  # Get top-most Y coordinate\n",
        "            data.append((text, confidence, x_min, y_min))\n",
        "\n",
        "    # Sort data: First by Y (rows), then by X (columns)\n",
        "    data.sort(key=lambda x: (x[3], x[2]))\n",
        "\n",
        "    # Check if first row is a table title/description\n",
        "    table_title = None\n",
        "    if len(data) > 0 and len(data[0][0].split()) > 5:  # If first row is a long sentence\n",
        "        table_title = data.pop(0)[0]  # Remove title from data\n",
        "\n",
        "    # Group words into rows based on Y-coordinates\n",
        "    rows = []\n",
        "    current_row = []\n",
        "    current_y = None\n",
        "    threshold = 10  # Adjust for better row grouping\n",
        "\n",
        "    for word, confidence, x, y in data:\n",
        "        if current_y is None or abs(y - current_y) < threshold:\n",
        "            current_row.append(word)\n",
        "        else:\n",
        "            rows.append(current_row)\n",
        "            current_row = [word]\n",
        "        current_y = y\n",
        "\n",
        "    if current_row:\n",
        "        rows.append(current_row)\n",
        "\n",
        "    # Convert rows into a Pandas DataFrame\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    # Print as PrettyTable\n",
        "    table = PrettyTable()\n",
        "    table.field_names = [f\"Column {i+1}\" for i in range(df.shape[1])]  # Auto-generate column names\n",
        "\n",
        "    for row in df.values:\n",
        "        table.add_row(row)\n",
        "\n",
        "    print(\"\\n **Detected Table:**\")\n",
        "    if table_title:\n",
        "        print(f\" **Table Title:** {table_title}\\n\")  # Print the extracted table title separately\n",
        "    print(table)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gpMoFXtanEO",
        "outputId": "4043efbb-ba66-4652-8764-e00e2a51ae6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025/03/02 19:52:36] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/root/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/usr/local/lib/python3.11/dist-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
            "[2025/03/02 19:52:39] ppocr DEBUG: dt_boxes num : 23, elapsed : 0.13311052322387695\n",
            "[2025/03/02 19:52:39] ppocr DEBUG: cls num  : 23, elapsed : 0.32187700271606445\n",
            "[2025/03/02 19:52:41] ppocr DEBUG: rec_res num  : 23, elapsed : 2.0094048976898193\n",
            "\n",
            " **Detected Table:**\n",
            " **Table Title:** Table 1.Exposure to salinity reduces the growth of wheat plants\n",
            "\n",
            "+----------+----------+----------+----------+\n",
            "| Column 1 | Column 2 | Column 3 | Column 4 |\n",
            "+----------+----------+----------+----------+\n",
            "|  5days   | 10 days  |  Group   |  light   |\n",
            "|    12    | control  |  70.32   |  9010.5  |\n",
            "| 60.41.5* |  787.9*  |    12    |   test   |\n",
            "|  75.78.  | control  |    16    |   1003   |\n",
            "|  52.22   |  816.7   |    16    |   test   |\n",
            "| *P<0.05. |   None   |   None   |   None   |\n",
            "+----------+----------+----------+----------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from paddleocr import PaddleOCR\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "# Initialize PaddleOCR\n",
        "ocr_model = PaddleOCR(use_angle_cls=True, lang=\"en\")\n",
        "\n",
        "# Provide the path to the table image\n",
        "image_path = \"/content/scientific-table.jpg\"\n",
        "\n",
        "# Ensure the image exists before processing\n",
        "if not os.path.exists(image_path):\n",
        "    print(f\"Error: Image not found at {image_path}\")\n",
        "else:\n",
        "    # Run OCR on the image\n",
        "    result = ocr_model.ocr(image_path, cls=True)\n",
        "\n",
        "    # Extract detected text with bounding box positions\n",
        "    data = []\n",
        "    for line in result:\n",
        "        for word_info in line:\n",
        "            text, confidence, position = word_info[1][0], word_info[1][1], word_info[0]\n",
        "            x_min = min([coord[0] for coord in position])  # Left-most X coordinate\n",
        "            y_min = min([coord[1] for coord in position])  # Top-most Y coordinate\n",
        "            data.append((text, confidence, x_min, y_min))\n",
        "\n",
        "    # Sort data first by Y (rows), then by X (columns)\n",
        "    data.sort(key=lambda x: (x[3], x[2]))\n",
        "\n",
        "    # Detect the title (long first row)\n",
        "    table_title = None\n",
        "    if len(data) > 0 and len(data[0][0].split()) > 5:  # If first detected text is long\n",
        "        table_title = data.pop(0)[0]  # Extract and remove title\n",
        "\n",
        "    # Automatically determine column positions\n",
        "    x_positions = sorted(set([x[2] for x in data]))  # Unique X-coordinates\n",
        "    column_threshold = 20  # Adjust to control column merging\n",
        "    columns = []\n",
        "    for x in x_positions:\n",
        "        if not columns or abs(x - columns[-1]) > column_threshold:\n",
        "            columns.append(x)\n",
        "\n",
        "    # Assign words to rows and columns\n",
        "    rows = []\n",
        "    current_row = []\n",
        "    current_y = None\n",
        "    row_threshold = 10  # Adjust for better row grouping\n",
        "\n",
        "    for word, confidence, x, y in data:\n",
        "        if current_y is None or abs(y - current_y) < row_threshold:\n",
        "            current_row.append((word, x))\n",
        "        else:\n",
        "            rows.append(current_row)\n",
        "            current_row = [(word, x)]\n",
        "        current_y = y\n",
        "\n",
        "    if current_row:\n",
        "        rows.append(current_row)\n",
        "\n",
        "    # Sort words in each row by X position\n",
        "    structured_rows = []\n",
        "    for row in rows:\n",
        "        row.sort(key=lambda x: x[1])  # Sort by X-coordinate\n",
        "        structured_rows.append([word[0] for word in row])\n",
        "\n",
        "    # Pad rows to ensure equal column count\n",
        "    max_columns = len(columns)\n",
        "    for row in structured_rows:\n",
        "        while len(row) < max_columns:\n",
        "            row.append(None)  # Fill missing values with None\n",
        "\n",
        "    # Convert to a Pandas DataFrame\n",
        "    df = pd.DataFrame(structured_rows)\n",
        "\n",
        "    # Print as PrettyTable\n",
        "    table = PrettyTable()\n",
        "    table.field_names = [f\"Column {i+1}\" for i in range(df.shape[1])]  # Auto-generate column names\n",
        "\n",
        "    for row in df.values:\n",
        "        table.add_row(row)\n",
        "\n",
        "    print(\"\\n **Detected Table:**\")\n",
        "    if table_title:\n",
        "        print(f\" **Table Title:** {table_title}\\n\")  # Print the table title separately\n",
        "    print(table)\n",
        "\n",
        "    # Convert to JSON format\n",
        "    table_json = df.to_json(orient=\"records\")\n",
        "    print(\"\\n **JSON Output :**\")\n",
        "    print(table_json)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INxrcy-MbaHk",
        "outputId": "f453fd39-0f50-401c-c3b2-848abe19bfc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2025/03/02 19:56:14] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/root/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/root/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/usr/local/lib/python3.11/dist-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
            "[2025/03/02 19:56:15] ppocr DEBUG: dt_boxes num : 23, elapsed : 0.07697296142578125\n",
            "[2025/03/02 19:56:16] ppocr DEBUG: cls num  : 23, elapsed : 0.0691218376159668\n",
            "[2025/03/02 19:56:18] ppocr DEBUG: rec_res num  : 23, elapsed : 2.2366929054260254\n",
            "\n",
            " **Detected Table:**\n",
            " **Table Title:** Table 1.Exposure to salinity reduces the growth of wheat plants\n",
            "\n",
            "+----------+----------+----------+----------+\n",
            "| Column 1 | Column 2 | Column 3 | Column 4 |\n",
            "+----------+----------+----------+----------+\n",
            "|  Group   |  light   |  5days   | 10 days  |\n",
            "| control  |    12    |  70.32   |  9010.5  |\n",
            "|   test   |    12    | 60.41.5* |  787.9*  |\n",
            "| control  |    16    |  75.78.  |   1003   |\n",
            "|   test   |    16    |  52.22   |  816.7   |\n",
            "| *P<0.05. |   None   |   None   |   None   |\n",
            "+----------+----------+----------+----------+\n",
            "\n",
            " **JSON Output :**\n",
            "[{\"0\":\"Group\",\"1\":\"light\",\"2\":\"5days\",\"3\":\"10 days\"},{\"0\":\"control\",\"1\":\"12\",\"2\":\"70.32\",\"3\":\"9010.5\"},{\"0\":\"test\",\"1\":\"12\",\"2\":\"60.41.5*\",\"3\":\"787.9*\"},{\"0\":\"control\",\"1\":\"16\",\"2\":\"75.78.\",\"3\":\"1003\"},{\"0\":\"test\",\"1\":\"16\",\"2\":\"52.22\",\"3\":\"816.7\"},{\"0\":\"*P<0.05.\",\"1\":null,\"2\":null,\"3\":null}]\n"
          ]
        }
      ]
    }
  ]
}